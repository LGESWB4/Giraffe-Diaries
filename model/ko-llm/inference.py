import os
import subprocess

# **GGUF ëª¨ë¸ ë° ì‹¤í–‰ íŒŒì¼ ê²½ë¡œ**
LLAMA_CLI_PATH = "/home/moons98.in/Giraffe-Diaries/llama.cpp/build/bin/llama-cli"

BASE_PATH = "/home/moons98.in/Giraffe-Diaries/model/ko-llm/weights/"
GGUF_MODEL_PATH = os.path.join(BASE_PATH, "Llama-3-Mopeyfied-Psychology-v2.Q4_K_M.gguf")

def run_chat():
    """
    `llama-cli` ì‹¤í–‰ í›„ ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ëŒ€í™” ì§„í–‰.
    `/exit` ì…ë ¥ ì‹œ ì¢…ë£Œ.
    """
    print("ğŸ“ AI ì±—ë´‡ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ '/exit'ì„ ì…ë ¥í•˜ì„¸ìš”.")

    try:
        subprocess.run(
            [LLAMA_CLI_PATH, "-m", GGUF_MODEL_PATH, "-cnv","--interactive", "--simple-io"],
            check=True
        )
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Chatbot shutting down.")

if __name__ == "__main__":
    run_chat()
