qai_hub_models[llama-v3_2-3b-chat-quantized]
transformers 
accelerate
huggingface_hub[cli]
huggingface_hub 
torch==2.4.1 
torchvision 
torchaudio

jupyter
ipykernel
